# Whisper data import

Metrictank comes with a set of tools to import Whisper data into the chunk format used by Metrictank. 
The usage of the tools is documented on [this page](https://github.com/grafana/metrictank/blob/master/docs/tools.md)([reader](https://github.com/grafana/metrictank/blob/master/docs/tools.md#mt-whisper-importer-reader)/[writer](https://github.com/grafana/metrictank/blob/master/docs/tools.md#mt-whisper-importer-writer)), this document specifically focuses on how the import procedure of Whisper files works.

## Import procedure

### Determination of metric names

The importer utility walks recursively through the whisper directory, looking for files which end with `.wsp`. If there is a name filter defined it additionally filters all the discovered files by the given pattern. It then generates the metric name by removing the prefix defined via the `-whisper-directory` parameter from the file's path, removing the string `.wsp` suffix, and replacing all the `/` characters with `.`.

For example if a file is located at `/opt/graphite/storage/my/metric/name.wsp` and the value given to `-whisper-directory` is `/opt/graphite/storage`, then the resulting metric name would be `my.metric.name`.

Additionally there is an optional parameter called `-name-prefix` which allows the caller to prefix all metric names with a given string, which needs to include the tailing `.` if it is wanted. In the above example, if the value of `-name-prefix` is `my.prefix.` then the resulting metric name would by `my.prefix.my.metric.name`.

### Schema conversion

The whisper importer reader requires the user to provide the path to the storage schemas used at the import destination (not the one on the source graphite installation), it then reads and parses those schemas. During the import it iterates over all the whisper files that need to be imported and processes each of them as following:

* Reads all the headers and points
* Generates the MetricData, interval gets set to the raw interval of the destination schema
* Iterates over each archive in the destination schema (raw + all rollups), for each destination archive it uses the schema conversion logic described [here](https://github.com/grafana/metrictank/blob/master/docs/schema-conversion-logic.md) to generate the archive points
* Generates chunks from the points which have been generated by the schema conversion logic
* Chunks are then sent to the importer-writer, which writes them into the store used by the destination cluster

Note that this conversion allows to convert from one storage-schema to another, but it does not support changes to the storage-aggregations.