package expr

import (
	"errors"
	"fmt"
	"io"

	"github.com/raintank/metrictank/api/models"
)

type Req struct {
	Query string
	From  uint32 // from for this particular pattern
	To    uint32 // to for this particular pattern
}

type Plan struct {
	Reqs          []Req
	exprs         []*expr
	MaxDataPoints uint32
	From          uint32                  // global request scoped from
	To            uint32                  // global request scoped to
	input         map[Req][]models.Series // input data to work with. set via Run()
	// new data generated by processing funcs. useful for two reasons:
	// 1) reuse partial calculations e.g. queries like target=movingAvg(sum(foo), 10)&target=sum(foo)A (TODO)
	// 2) central place to return data back to pool when we're done.
	generated map[Req][]models.Series
}

func (p Plan) Dump(w io.Writer) {
	fmt.Fprintf(w, "Plan:\n")
	fmt.Fprintf(w, "* Exprs:\n")
	for _, e := range p.exprs {
		fmt.Fprintln(w, e.Print(2))
	}
	fmt.Fprintf(w, "* Reqs:\n")
	for _, r := range p.Reqs {
		fmt.Fprintln(w, "   ", r)
	}
	fmt.Fprintf(w, "MaxDataPoints: %d\n", p.MaxDataPoints)
	fmt.Fprintf(w, "From: %d\n", p.From)
	fmt.Fprintf(w, "To: %d\n", p.To)
}

// Plan validates the expressions and comes up with the initial (potentially non-optimal) execution plan
// which is just a list of requests and the expressions.
// traverse tree and as we go down:
// * make sure function exists
// * tentative validation pre function call (number of args and type of args, to the extent it can be done in advance),
// * let function validate input arguments further (to the extend it can be done in advance)
// * allow functions to extend the notion of which data is required
// * future version: allow functions to mark safe to pre-aggregate using consolidateBy or not
func NewPlan(exprs []*expr, from, to, mdp uint32, stable bool, reqs []Req) (Plan, error) {
	var err error
	for _, e := range exprs {
		reqs, err = newplan(e, from, to, stable, reqs)
		if err != nil {
			return Plan{}, err
		}
	}
	return Plan{
		Reqs:          reqs,
		exprs:         exprs,
		MaxDataPoints: mdp,
		From:          from,
		To:            to,
	}, nil
}

func newplan(e *expr, from, to uint32, stable bool, reqs []Req) ([]Req, error) {
	if e.etype != etFunc && e.etype != etName {
		return nil, errors.New("request must be a function call or metric pattern")
	}
	if e.etype == etName {
		reqs = append(reqs, Req{
			e.str,
			from,
			to,
		})
		return reqs, nil
	}

	// here e.type is guaranteed to be etFunc
	fdef, ok := funcs[e.str]
	if !ok {
		return nil, ErrUnknownFunction(e.str)
	}
	if stable && !fdef.stable {
		return nil, ErrUnknownFunction(e.str)
	}

	// now comes the interesting task of validating the arguments as specified by the function,
	// against the arguments that were parsed.

	fn := fdef.constr()
	argsExp, _ := fn.Signature()

	// note that signature may have seriesLists in it, which means one or more args of type seriesList
	// so it's legal to have more e.args then (signature) args in that case.
	if len(e.args) < len(argsExp) {
		return nil, ErrMissingArg
	}
	// j tracks pos in e.args of next given arg to process
	j := 0
	for _, argExp := range argsExp {
		// we can't do extensive, accurate validation of the type here because what the output from a function we depend on
		// might be dynamically typed. e.g. movingAvg returns 1..N series depending on how many it got as input
		if len(e.args) <= j {
			return nil, ErrMissingArg
		}
		argGot := e.args[j]
		switch argExp {
		case series:
			if argGot.etype != etName && argGot.etype != etFunc {
				return nil, ErrBadArgumentStr{"func or name", string(argGot.etype)}
			}
		case seriesList:
			if argGot.etype != etName && argGot.etype != etFunc {
				return nil, ErrBadArgumentStr{"func or name", string(argGot.etype)}
			}
		case seriesLists:
			if argGot.etype != etName && argGot.etype != etFunc {
				return nil, ErrBadArgumentStr{"func or name", string(argGot.etype)}
			}
			// special case! consume all subsequent args (if any) in e.args that will also yield a seriesList
			for len(e.args) > j+1 && (e.args[j+1].etype == etName || e.args[j+1].etype == etFunc) {
				j += 1
			}
		case integer:
			if argGot.etype != etConst {
				return nil, ErrBadArgumentStr{"int", string(argGot.etype)}
			}
		case float:
			if argGot.etype != etConst {
				return nil, ErrBadArgumentStr{"float", string(argGot.etype)}
			}
		case str:
			if argGot.etype != etString {
				return nil, ErrBadArgumentStr{"string", string(argGot.etype)}
			}
		}
		j += 1
	}
	// when we stop iterating, j should be a non-existent pos
	if len(e.args) > j {
		return nil, ErrTooManyArg
	}
	err := fn.Init(e.args)
	if err != nil {
		return nil, err
	}
	from, to = fn.NeedRange(from, to)
	// look at which arguments are requested
	// if the args are series, they are to be requested with the potentially extended to/from
	// if they are not, keep traversing the tree until we find out which metrics to fetch and for which durations
	for _, arg := range e.args {
		if arg.etype == etName || arg.etype == etFunc {
			reqs, err = newplan(arg, from, to, stable, reqs)
			if err != nil {
				return nil, err
			}
		}
	}
	return reqs, nil
}

// Run invokes all processing as specified in the plan (expressions, from/to) with the input as input
func (p Plan) Run(input map[Req][]models.Series) ([]models.Series, error) {
	var out []models.Series
	p.input = input
	p.generated = make(map[Req][]models.Series)
	for _, expr := range p.exprs {
		o, err := p.run(p.From, p.To, expr)
		if err != nil {
			return nil, err
		}
		out = append(out, o...)
	}
	return out, nil
}

func (p Plan) run(from, to uint32, e *expr) ([]models.Series, error) {
	if e.etype != etFunc && e.etype != etName {
		panic("this should never happen. request must be a function call or metric pattern")
	}
	if e.etype == etName {
		req := Req{
			e.str,
			from,
			to,
		}
		return p.input[req], nil
	}

	// here e.type is guaranteed to be etFunc
	fdef, ok := funcs[e.str]
	if !ok {
		panic(fmt.Sprintf("cannot find func %q. this should never happen as we should have validated function existence earlier", e.str))
	}
	fn := fdef.constr()
	err := fn.Init(e.args)
	if err != nil {
		return nil, err
	}
	from, to = fn.NeedRange(from, to)
	// look at which arguments are requested
	// if the args are series, they are to be requested with the potentially extended to/from
	// if they are not, keep traversing the tree until we find out which metrics to fetch and for which durations
	results := make([]interface{}, len(e.args))
	for i, arg := range e.args {
		if arg.etype == etName || arg.etype == etFunc {
			result, err := p.run(from, to, arg)
			if err != nil {
				return nil, err
			}
			results[i] = result
		} else if arg.etype == etString {
			results[i] = arg.str
		} else {
			// etype == etConst
			results[i] = arg.float
		}
	}
	// we now have all our args and can process the data and return
	rets, err := fn.Exec(p.generated, results...)
	if err != nil {
		return nil, err
	}
	series := make([]models.Series, len(rets))
	for i, ret := range rets {
		series[i] = ret.(models.Series)
	}
	return series, nil
}

// Clean returns all buffers (all input data + generated series along the way)
// back to the pool.
func (p Plan) Clean() {
	for _, series := range p.input {
		for _, serie := range series {
			pointSlicePool.Put(serie.Datapoints[:0])
		}
	}
	for _, series := range p.generated {
		for _, serie := range series {
			pointSlicePool.Put(serie.Datapoints[:0])
		}
	}
}
