regarding when to allocate models.Series (or more precisely, their []schema.Point attribute), there's 2 main choices:

1) copy-on-write:
- each function does not modify data in their inputs, they allocate new slices (or better: get from pool) etc to save output computations
- storing data into new slice can be done in same pass as processing the data
- potentially many of these steps in a sequence if you have lots of processing steps in a row
- getting a slice from the pool may cause a stall if it's not large enough and runtime needs to re-allocate and copy
- allows us to pass the same data into multiple processing steps

2)copy in advance:
- give each processing step a copied slice in which they can do whatever they want (e.g. modify in place)
- works well if you have many processing steps in a row that can just modify in place
- copying up front, in a separate pass. also causes a stall
- often copying may be unnessary, but we can't know that in advance (unless we expand the expr tree to mark whether it'll do a write)


I'm going to assume that multi-steps in a row is not that common, and COW seems more commonly the best approach


This leaves the problem of effectively managing allocations and using a sync.Pool.
Note that the expr library can be called by different clients (MT, grafana, graphite-ng, ...)
It's up to the client to instantiate the pool, and set up the default allocation to return point slices of desired point capacity.
The client can then of course use this pool to store series, which it then feeds to expr.
expr library does the rest.  It manages the series/pointslices and gets new ones as a basis for the COW.
Once the data is returned to the client, and the client is done using the returned data, it should call plan.Clean(),
which returns all data back to the pool  (both input data or newly generated series, whether they made it into the final output or not).

note that individual processing functions only request slices from the pool, they don't put anything on it.
e.g. an avg of 3 series will create 1 new series (from pool), but won't put the 3 inputs back in the pool, because
another processing step may require the same input data.

